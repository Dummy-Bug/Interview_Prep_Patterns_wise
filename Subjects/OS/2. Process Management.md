# Process Management

Note: Kernel is the first process to be created, is the ancestor of all other processes and is at the root of the process tree.

<br>

## @ Process Basics & Scheduling 

### 1. How does a process look like in memory ?
When a program is created then it is just some pieces of Bytes which is stored in Hard Disk as a passive entity. When a program is loaded in memory it becomes an active entity known as **Process**.

![img](https://www.tutorialspoint.com/assets/questions/media/29467/1.jpg)

**Code (or Text)**

This section of memory contains the executable instructions of a program. It is read-only segment.

**Data**

It contains the global and static variables that are initialized by the programmer prior to the execution of a program. This segment is not read-only, as the value of the variables can be changed at the runtime.

**Stack**

It contains temporary data i.e. function parameters, return addresses, and local variables. Stack grows in opposite direction of heap for avoiding overlapping problem. This section is committed to store all the data needed by a function call in a program. A stack pointer register keeps the tracks of the top of the stack i.e., how much of the stack area using by the current process.

**Heap**

To allocate memory for variables whose size cannot be statically determined by the compiler before program execution, requested by the programmer, there is a requirement of dynamic allocation of memory which is done in heap segment. It can be only determined at run-time. It is managed via system calls to malloc, calloc, free, delete etc.

<br>

[Working Of Stack Vs Heap Memory](https://www.youtube.com/watch?v=PdvGEI-P3-M)

<br>


### 2. Process States

![img](https://media.geeksforgeeks.org/wp-content/uploads/20190604122001/states_modified.png)

<br>

### 3. CPU and IO Bound Processes
If the process is intensive in terms of CPU operations then it is called CPU bound process. Similarly, If the process is intensive in terms of I/O operations then it is called IO bound process. For better performance, we should choose proper mix of CPU bound and I/O bound processes.

<br>

### 4. Zombie process (or Defunct process)
A zombie process is a process that has terminated but its PCB still exists because its parent has not yet accepted its return value. Those Processes has completed their execution by exit() system call but still has an entry in Process Table. It is a process in terminated state.

**Maximum number of Zombie process a system can handle?**

It will depend upon system configuration and strength.

<br>

### 5. PCB (Process Control Block)
PCB is used to track the process’s execution status. When process makes a transition from one state to another, OS must update information in the process’s PCB. It contains following info:
1. Process Number
2. Process State
3. Program Counter (stores address of next instruction)
4. Register
5. Memory info
6. Open file lists

<br>

### 6. Process Scheduling Queues
OS maintains all PCBs in Process Scheduling Queues. 
1. Job Queue: keeps track of all newly created process.
2. Ready Queue: Keeps track of all process residing in main memory and are ready and waiting to execute.
3. Device Queue: Every device has its own device queue.

<br>

### 7. Types of schedulers

**Long term** – performance 

Makes a decision about how many processes while reside in the ready state, this **decides the degree of multiprogramming**.

<br>

**Short term** – Context switching time 

Short term scheduler will **decide which process to be executed** next and then it will call dispatcher. A dispatcher is a software that moves process from ready to run and vice versa. In other words, it is context switching.

<br>

**Medium term** – Swapping time 

Medium term scheduler is **used for swapping** i.e. moving the process from main memory to secondary and vice versa.

<br>

### 8. Dispatcher
A dispatcher is the module of the operating system that gives control of the CPU to the process selected by the CPU scheduler. **Dispatch latency** is the time taken to stop a process and start another. Dispatch latency is a pure overhead.

<br>

### 9. What happens during Context Switch ?
During Context Switch, the state of current running process is stored in its PCB. After this, the state of the process to run next is loaded from its own PCB and used to set the PC, registers, etc. 

![img](https://www.tutorialspoint.com/operating_system/images/context_switch.jpg)

Context switches are computationally intensive since register and memory state must be saved and restored. To avoid the amount of context switching time, some hardware systems employ two or more sets of processor registers.

<br>

### 10. Scheduling Chart

![img](https://github.com/naman14310/Interview_Prep/blob/main/Subjects/OS/scheduling%20chart%20os.png)

<br>

### 11. Which is the Best Scheduling Algorithm ?
Every scheduling algorithm has a type of a situation where it is the best choice. Let's look at different such situations:

<br>

Case 1: If Incoming processes are short with no specific priority

**FCFS** works best when compared to SJF and RR because the processes are short which means that no process will wait for a longer time. When each process is executed one by one, every process will be executed eventually.

<br>

Case2: If processes are a mix of long and short processes and the task will only be completed if all the processes are executed successfully in a given time.

**Round Robin scheduling** works efficiently here because it does not cause starvation and also gives equal time quantum for each process. Round-robin will adjust the average waiting time for all process.

<br>

Case 3: The processes are a mix of user based and kernel based processes.

**Priority based scheduling** works efficiently in this case because generally kernel based processes have higher priority when compared to user based processes.

<br>

### 12. Which scheduling algorithm is used in Linux, Windows and Android ?
```
Linux      :      Completely Fair Scheduling (CFS) algorithm
Windows    :      Multilevel feedback queue (combination of fixed-priority preemptive scheduling, round-robin, and FCFS)
Android    :      O(1) scheduling algorithm (based on Linux Kernel 2.6)
```

<br>

### 13. What is Starvation and Aging ?
Starvation or indefinite blocking is phenomenon, in which a process ready to run for CPU can wait indefinitely because of low priority. **Aging** is a technique of gradually increasing the priority of processes that wait in the system for a long time.

Note: Starvation is different from deadlock as it occurs due to not getting access to CPU becoz of low priority, while deadlock occurs due to circular waiting of resources.

<br>

### 14. Inter Process Communication (IPC)
Inter-process communication (IPC) is a mechanism that allows processes to communicate with each other and synchronize their actions. Processes can communicate with each other through:
1. Shared Memory
2. Message passing

![img](https://forns.lmu.build/assets/images/spring-2018/cmsi-387/week-8/ipc-1.png)

**Shared Memory Method**

Processes can use shared memory for extracting information as a record from another process as well as for delivering any specific information to other processes. Eg: Producer-Consumer problem 

<br>

**Message Passing Method**

If two processes p1 and p2 want to communicate with each other, they proceed as follows:
1. Establish a communication link (if a link already exists, no need to establish it again.)
2. Start exchanging messages using basic primitives.

We need at least two primitives: 

– send(message, destination) or send(message) 

– receive(message, host) or receive(message)

[Detailed Explaination](https://www.geeksforgeeks.org/inter-process-communication-ipc/)

<br>



## @ Process Synchronisation
Two processes are said to be **Independent** if the execution of one process does not affect the execution of another process. Two processes are said to be **Cooperative** if the execution of one process affects the execution of another process. These processes need to be synchronized so that the order of execution can be guaranteed.

<br>

### 1. Race Condition
It is a situation where several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the accesses take place. To avoid such situations, it must be ensured that only one process can manipulate the data at a given time. 

<br>

### 2. Critical Section
1. Each process has a section of code, called the critical section, in which the process access shared resources, changes common variables and files.
2. The problem is to ensure that when one process is executing in its critical section then no other process can execute its own critical section
3. The critical section is preceded by an *entry section* in which a process seeks permission from other processes. The critical section is followed by an *exit section.*

<br>

### 3. Priority inversion
A low-priority process gets the priority of a high-priority process waiting for it.

<br>

### 4. Condition for Synchronisation mechanisms
A solution to the critical section problem must satisfy the following properties:
1. Mutual exclusion
2. Progress 
3. Bounded waiting
4. Architectural Neutrality

<br>

### 5. Busy Waiting
Busy waiting means that a process is waiting for a condition to be satisfied in a tight loop without releasing the processor. It can be avoided but incurs the overhead associated with putting a process to sleep and having to wake it up when the appropriate program state is reached.

<br>

### 6. SpinLocks
1. Spinlock is a synchronisation mechanism, a process is waiting for lock will keep the processor busy by continuously polling the lock. 
2. It is a Busy Waiting solution and is usually used when there is low contention of resources for short period of time.
3. Spinlocks can be used only for mutual exclusion.	

<br>

### 7. Semaphores
A semaphore is an integer variable that, apart from initialization, is accessed only through two atomic operations called wait() and signal().

```cpp
wait() is used for acquiring lock

wait(S){
    while(S<=0);    // --> Busy Waiting
    S--;
}


signal() is used for releasing lock

signal(S){
    S++;
}
```

<br>

### 8. Binary Semaphores (Mutexes)
It is used to implement solution of critical section problem with multiple processes. Initialized to 1.

Note: The use of a mutex decreases parallelism.

```cpp
struct semaphore {
    enum value(0, 1);                 // --> Since it is Binary Semaphore, it'll only contains 0 or 1
  
    /* q contains all Process Control Blocks (PCBs) corresponding to processes got blocked while performing wait() operation */
    
    queue<process> q;
}; 


wait(semaphore s){
    if (s.value == 1) {
        s.value = 0;
    }
    else {
        q.push(P);                  // --> add the process to the waiting queue
        sleep();
    }
}


signal(Semaphore s){
    if (s.q is empty()) {
        s.value = 1;
    }
    else {  
        Process p=q.pop();         // --> select a process from waiting queue and give entry to critical section
        wakeup(p);
    }
}
```

<br>

### 9. Counting semaphore
It is used to control access to a resource that has multiple instances. Initialized to n, where n is the number of resources.

```cpp
struct Semaphore {
    int value;                    // --> Since it is counting semaphore, It will contain any integer val depends on number of resources 
    Queue<process> q;
};


wait(Semaphore s){
    s.value = s.value - 1;
    if (s.value < 0) {
        q.push(p);               // --> add process to queue here p is a process which is currently executing
        block();
    }
    else
        return;
}
  
  
signal(Semaphore s){
    s.value = s.value + 1;
    if (s.value <= 0) {
        Process p=q.pop();      // --> remove process p from queue
        wakeup(p);
    }
    else
        return;
}
```

<br>

### 10. Do Semaphore suffers from deadlock
Semaphores may lead to indefinite wait (starvation) and deadlocks.

```cpp
Example of two prcoess, where use of semaphores leads to deadlock

   P0                            P1
   
 wait (S);                    wait (Q);
 wait (Q);                    wait (S);
  ...                           ...
signal (S);                  signal (Q);
signal (Q);                  signal (S);
```

<br>



## @ Classical Synchronisation Problems

### 1. Producer Consumer Problem (Bounded Buffer)
We have a buffer of fixed size. A producer can produce an item and can place in the buffer. A consumer can pick items and can consume them. We need to ensure that when a producer is placing an item in the buffer, then at the same time consumer should not consume any item. In this problem, buffer is the critical section. 

To solve this problem, we need two counting semaphores – Full and Empty. “Full” keeps track of number of items in the buffer at any given time and “Empty” keeps track of number of unoccupied slots. 

```cpp
Initialization of semaphores:

mutex = 1; 
Full = 0;               // --> Initially, all slots are empty. Thus full slots are 0 
Empty = n;              // --> All slots are empty initially 

/* --------------------------------------------------------------------------------------------------*/

Solution for Producer:

do {
    produce_item();

    wait(empty);
    wait(mutex);

    place_in_buffer();

    signal(mutex);
    signal(full);

} while(true)

/* --------------------------------------------------------------------------------------------------*/

Solution for Consumer:

do {

    wait(full);
    wait(mutex);

    remove_item_from_buffer();

    signal(mutex);
    signal(empty);

    consume_item();

} while(true)
```

<br>

### 2. Reader Writer Problem
Consider a situation where we have a file shared between many people. Then,
1. If one of the people tries editing the file, no other person should be reading or writing at the same time.
2. However if some person is reading the file, then others may read it at the same time.

<br>

**Solution when Reader has the Priority over Writer**

Here priority means, no reader should wait if the share is currently opened for reading. Three variables are used: mutex, wrt, readcnt to implement solution.


```cpp
/*
    mutex   : used to ensure mutual exclusion when readcnt is updated i.e. when any reader enters or exit from the critical section.
    wrt     : used to restrict access of writers if atleast 1 reader is present.
    readcnt : tells the number of processes performing read in the critical section, initially 0.
*/

semaphore mutex, wrt;           
int readcnt;  

/* ---------------------------------------------------------------------------------------*/

Writer process:

do {
    wait(wrt);                      // --> writer requests for critical section
    write();
    signal(wrt);                    // --> leaves the critical section

} while(true);

/* ---------------------------------------------------------------------------------------*/

Reader process:

do {
   wait(mutex);         // --> Reader wants to enter the critical section (mutex is used to ensure mutual exclusion on readcnt)
   
   readcnt++;           // --> The number of readers has now increased by 1                   

   /*   
        If there is atleast one reader in the critical section
        we will ensure that no writer can enter..
        thus we give preference to readers here
   */
   
   if (readcnt==1)     
      wait(wrt);                    

   signal(mutex);       // --> other readers can enter while this current reader is inside the critical section (hence release mutex) 


   reading();
   
   
   wait(mutex);         // --> a reader wants to leave, again we will apply acquire lock on mutex before changing readcnt value

   readcnt--;

   /* 
        If no reader is left in the critical section,
        release wrt lock so that writer can perform their actions
   */
    
   if (readcnt == 0) 
       signal(wrt);         

   signal(mutex);       // --> reader leaves and releasing mutex lock

} while(true);

```

<br>

### 3. Dinning Philosopher Problem
The Dining Philosopher Problem states that K philosophers seated around a circular table with one chopstick between each pair of philosophers. A philosopher may eat if he can pick up the two chopsticks adjacent to him. One chopstick may be picked up by any one of its adjacent followers but not both. 

```cpp
Semaphores:

chopsticks[5];      // --> all semaphores initialized to 1

Pi:

do { 
    wait (chopstick[i]);            // --> acquire lock on left chopstick
    wait (chopStick[(i+1)%5]);      // --> acquire lock on right chopstick
    
    eat()
    
    signal (chopstick[i]);          // --> release lock for left
    signal (chopstick[(i+1)%5]);    // --> release lock for right
    
} while (true);
```

Above system may suffer from deadlock if all philosopher pick there left chopstick at same instant. 

**Solution for Deadlock:** We make (n-1) philospher to pick left chopstick first and we will reverse the order for 1 philosopher so he will pick his right chopstick first.

<br>


## @ Synchronisation Mechanisms in C++

[Best Article](https://medium.com/swlh/c-mutex-write-your-first-concurrent-code-69ac8b332288)

### 1. Mutex Implementation 
Hold a lock only for the operations that actually require it.

```cpp
#include<iostream>
#include <mutex>
#include <vector>
using namespace std;

mutex door;                      // --> mutex declaration
vector<int> v;                   // --> shared data

door.lock();                     // --> acquiring lock i.e. wait()

/*-----------------------*/

This is a thread-safe zone: just one thread at the time allowed
  
Unique ownership of vector v guaranteed 

/*-----------------------*/

door.unlock();                   // --> releasing lock i.e. signal()
```

<br>

### 2. Non blocking mutex
1. `try_lock()` is a non-blocking method offered by `std::mutex`. It returns immediately, even if the acquisition failed, with a value of true if the mutex is acquired, false if not.
2. `std::timed_mutex` offers two non-blocking methods for locking the mutex: `try_lock_for()` and `try_lock_until()`, both returning when the time elapsed with a true or false value based on the acquisition success.

<br>

### 3. What happens if we forget to unlock() or any exception is thrown before it ?
The unlock() will never be executed. The resource will be unavailable during all the mutex lifetime, and if destroyed, the behavior is undefined.

<br>

### 4. Lock Gaurd
It always guarantees to unlock the mutex using RAII (Resource Acquisition Is Initialization) paradigm: the raw mutex is encapsulated inside a lock_guard that invokes lock() at its construction and unlock() at its destruction, when it exits its scope. This is safe even in case of exceptions.

```cpp
#include<iostream>
#include <mutex>
#include <vector>
using namespace std;

mutex door;                         // --> mutex declaration
vector<int> v;                      // --> shared data

{     
     lock_guard<mutex> lg(door);    // --> lg Constructor called. Equivalent to door.lock();
      
     /*-----------------------*/
       
     Unique ownership of vector guaranteed..
    
     /*-----------------------*/
     
}                                   // --> lg exits its scope. Destructor called. Equivalent to door.unlock();
```

<br>

